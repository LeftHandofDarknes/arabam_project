import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time

# KullanÄ±cÄ± filtreleri
MAX_KM = 150000
MAX_PRICE = 1750000
MAX_AGE = 10
CURRENT_YEAR = 2025

# Arabam.com'dan marka ve model bilgilerini Ã§ek
@st.cache_data
def get_brands():
    url = "https://www.arabam.com/ikinci-el/otomobil"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")
    brands = [a.text.strip() for a in soup.select(".filter-list a")]
    return brands

@st.cache_data
def get_models(brand):
    url = f"https://www.arabam.com/ikinci-el/{brand.lower().replace(' ', '-')}-modelleri"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")
    models = [a.text.strip() for a in soup.select(".filter-list a")]
    return models

@st.cache_data
def get_submodels(brand, model):
    url = f"https://www.arabam.com/ikinci-el/{brand.lower().replace(' ', '-')}/{model.lower().replace(' ', '-')}-modelleri"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")
    submodels = [a.text.strip() for a in soup.select(".filter-list a")]
    return submodels

# Belirtilen sayfadan ilanlarÄ± Ã§ekme fonksiyonu
def get_listings(brand, model, submodel):
    url = f"https://www.arabam.com/ikinci-el/{brand.lower().replace(' ', '-')}/{model.lower().replace(' ', '-')}/{submodel.lower().replace(' ', '-')}"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")
    listings = []

    for row in soup.select(".listing-item"):  # Arabam.com'daki her ilanÄ± seÃ§
        try:
            year = int(row.select_one(".year").text.strip())
            km = int(row.select_one(".km").text.strip().replace(".", ""))
            price = int(row.select_one(".price").text.strip().replace(" TL", "").replace(".", ""))
            title = row.select_one(".title").text.strip()
            location = row.select_one(".location").text.strip()
            link = "https://www.arabam.com" + row.select_one("a")["href"]
            
            # KullanÄ±cÄ± kriterlerine gÃ¶re filtreleme
            if (CURRENT_YEAR - year) <= MAX_AGE and km <= MAX_KM and price <= MAX_PRICE:
                listings.append({
                    "Model": model,
                    "Ä°lan BaÅŸlÄ±ÄŸÄ±": title,
                    "YÄ±l": year,
                    "Kilometre": km,
                    "Fiyat": price,
                    "Ä°l / Ä°lÃ§e": location,
                    "Ä°lan URL": link
                })
        except:
            continue

    return listings

# Streamlit UI
def main():
    st.set_page_config(page_title="Arabam.com Veri ToplayÄ±cÄ±", page_icon="ðŸš—", layout="wide")
    st.title("ðŸš— Arabam.com Veri ToplayÄ±cÄ±")
    st.write("Belirli kriterlere gÃ¶re Arabam.com'dan ikinci el araÃ§ ilanlarÄ±nÄ± Ã§ekin ve analiz edin.")

    # Marka SeÃ§imi
    brands = get_brands()
    brand = st.selectbox("LÃ¼tfen bir marka seÃ§in:", brands)

    if brand:
        models = get_models(brand)
        model = st.selectbox("LÃ¼tfen bir model seÃ§in:", models)
        
        if model:
            submodels = get_submodels(brand, model)
            submodel = st.selectbox("LÃ¼tfen bir alt model seÃ§in:", submodels)

            if st.button("Verileri Ã‡ek"):
                st.info(f"'{brand} {model} {submodel}' iÃ§in veriler Ã§ekiliyor...")
                listings = get_listings(brand, model, submodel)
                
                if listings:
                    df = pd.DataFrame(listings)
                    st.dataframe(df)
                    
                    # Excel dosyasÄ± olarak indir
                    output_file = "arabam_data.xlsx"
                    df.to_excel(output_file, index=False)
                    with open(output_file, "rb") as f:
                        st.download_button("Verileri Ä°ndir", f, file_name=output_file)
                else:
                    st.warning("Filtrelere uygun ilan bulunamadÄ±.")

if __name__ == "__main__":
    main()
