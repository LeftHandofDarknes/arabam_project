import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from io import BytesIO

# Belirlenen araÃ§ marka ve modelleri
MARKA_MODELLER = {
    "Audi": ["A3"],
    "BMW": ["3 Serisi"],
    "Ford": ["Focus"],
    "Honda": ["Civic"],
    "Hyundai": ["i20"],
    "Mercedes-Benz": ["C Serisi"],
    "Renault": ["Clio", "Megane", "Symbol"],
    "Skoda": ["Octavia", "SuperB"],
    "Toyota": ["Corolla"],
    "Volkswagen": ["Polo", "Passat", "Golf"]
}

BASE_URL = "https://www.arabam.com/ikinci-el"

# Arabam.com iÃ§in sabit filtreler
MIN_YIL = 2015
MAX_KM = 150000
MAX_FIYAT = 1750000  # 1.750.000 TLâ€™den pahalÄ± olanlar alÄ±nmayacak

st.title("ğŸš— Arabam.com Veri ToplayÄ±cÄ±")
st.write("Belirli kriterlere gÃ¶re Arabam.com'dan ikinci el araÃ§ ilanlarÄ±nÄ± Ã§ekin ve analiz edin.")

# KullanÄ±cÄ±dan araÃ§ marka seÃ§imi
marka_secim = st.selectbox("LÃ¼tfen bir marka seÃ§in:", list(MARKA_MODELLER.keys()))

# SeÃ§ilen markanÄ±n modellerini listeleme
model_secim = st.selectbox("LÃ¼tfen bir model seÃ§in:", MARKA_MODELLER[marka_secim])

# Veri Ã§ekme butonu
if st.button("Verileri Ã‡ek"):
    with st.spinner(f"{marka_secim} {model_secim} iÃ§in veriler Ã§ekiliyor..."):
        try:
            # Arabam.com iÃ§in uygun URL oluÅŸturma
            url = f"{BASE_URL}/{marka_secim.lower()}-{model_secim.lower()}?minYear={MIN_YIL}&maxkm={MAX_KM}&maxPrice={MAX_FIYAT}"
            headers = {"User-Agent": "Mozilla/5.0"}
            response = requests.get(url, headers=headers)

            if response.status_code != 200:
                st.error("Arabam.com ile baÄŸlantÄ± kurulamadÄ±. LÃ¼tfen tekrar deneyin.")
            else:
                # Sayfa kaynaÄŸÄ±nÄ± iÅŸle
                soup = BeautifulSoup(response.text, "html.parser")
                ilanlar = []
                
                # Ä°lanlarÄ± Ã§ekme
                for ilan in soup.find_all("tr", class_="listing-item"):
                    try:
                        model = ilan.find("td", class_="listing-modelname").text.strip()
                        ilan_baslik = ilan.find("td", class_="listing-title").text.strip()
                        yil = ilan.find("td", class_="listing-year").text.strip()
                        km = ilan.find("td", class_="listing-km").text.strip().replace(".", "")
                        fiyat = ilan.find("td", class_="listing-price").text.strip().replace(" TL", "").replace(".", "")
                        il_ilce = ilan.find("td", class_="listing-location").text.strip()
                        ilan_url = "https://www.arabam.com" + ilan.find("a")["href"]

                        ilanlar.append([model, ilan_baslik, yil, km, fiyat, il_ilce, ilan_url])
                    except:
                        continue
                
                # EÄŸer ilan yoksa hata gÃ¶ster
                if not ilanlar:
                    st.warning("Filtrelere uygun ilan bulunamadÄ±.")
                else:
                    # Veriyi tablo halinde gÃ¶ster
                    df = pd.DataFrame(ilanlar, columns=["Model", "Ä°lan BaÅŸlÄ±ÄŸÄ±", "YÄ±l", "Kilometre", "Fiyat", "Ä°l/Ä°lÃ§e", "Ä°lan URL"])
                    st.dataframe(df)
                    
                    # Excel dosyasÄ± olarak indirme butonu
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df.to_excel(writer, index=False, sheet_name="Arabam Ä°lanlarÄ±")
                    output.seek(0)
                    st.download_button(
                        label="ğŸ“¥ Verileri Excel olarak indir",
                        data=output,
                        file_name=f"{marka_secim}_{model_secim}_ilanlar.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
        except Exception as e:
            st.error(f"Bir hata oluÅŸtu: {e}")
